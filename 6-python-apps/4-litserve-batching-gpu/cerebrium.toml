[cerebrium.deployment]
name = "4-litserve-batching-gpu"
python_version = "3.12"
include = ["*"]
exclude = [".*"]
shell_commands = []

[cerebrium.runtime.custom]
port = 8000
entrypoint = ["python", "app/main.py"]
healthcheck_endpoint = "/health"

[cerebrium.hardware]
cpu = 2
memory = 4.0
compute = "AMPERE_A10"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
cooldown = 10
replica_concurrency = 4 # This should match the batch size

[cerebrium.dependencies.pip]
pydantic = "latest"
numpy = "latest"
loguru = "latest"
fastapi = "latest"
litserve = "latest"
transformers = "latest"
torch = "latest"