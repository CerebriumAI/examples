# This file was automatically generated by Cerebrium as a starting point for your project. 
# You can edit it as you wish.
# If you would like to learn more about your Cerebrium config, please visit https://docs.cerebrium.ai/cerebrium/environments/config-files#config-file-example

[cerebrium.build]
predict_data = "{\"prompts\": [\"Hello, my name is\", \"The president of the United States is\",\"The capital of France is\", \"The future of AI is\", \"What is your favourite holiday destination\"]}"
force_rebuild = false
hide_public_endpoint = false
disable_animation = false
disable_build_logs = false
disable_syntax_check = false
disable_predict = false
log_level = "INFO"
disable_confirmation = false
shell_commands = [
  "pip install neuronx-cc torch-neuronx transformers-neuronx --extra-index-url=https://pip.repos.neuron.amazonaws.com",
  "pip install sentencepiece huggingface_hub pydantic",
  "export LD_LIBRARY_PATH=$MICROMAMBA_DIR/envs/$BUILD_ENV:$LD_LIBRARY_PATH",
]

[cerebrium.deployment]
name = "11-inferentia-plain"
python_version = "3.10"
include = "[./*, main.py, cerebrium.toml]"
exclude = "[./example_exclude]"
cuda_version = "12"

[cerebrium.hardware]
region = "us-east-1"
provider = "aws"
gpu = "INF2"
cpu = 6
memory = 120.0
gpu_count = 1

[cerebrium.scaling]
min_replicas = 0
max_replicas = 5
cooldown = 60

[cerebrium.dependencies.pip]


[cerebrium.dependencies.conda]

[cerebrium.dependencies.apt]
wget = "latest"
