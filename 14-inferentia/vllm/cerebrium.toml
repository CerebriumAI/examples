# This file was automatically generated by Cerebrium as a starting point for your project. 
# You can edit it as you wish.
# If you would like to learn more about your Cerebrium config, please visit https://docs.cerebrium.ai/cerebrium/environments/config-files#config-file-example

[cerebrium.deployment]
name = "11-inferentia"
python_version = "3.10"
include = ["./*", "main.py", "cerebrium.toml"]
exclude = ["./example_exclude"]
shell_commands = [
    "pip install torch==2.1.* --index-url https://download.pytorch.org/whl/cpu",
    "pip install wget",
    "pip install awscli",
    "pip install neuronx-cc==2.* torch-neuronx==2.1.* torchvision transformers-neuronx --extra-index-url=https://pip.repos.neuron.amazonaws.com",
    "pip install ray huggingface_hub pydantic triton",
    "git clone https://github.com/vllm-project/vllm.git",
    "cd vllm && git checkout 6ef09b08f88b675f84b7140238286e5d4c5304c8 && pip install -U -r requirements-neuron.txt --extra-index-url=https://pip.repos.neuron.amazonaws.com && pip install . --extra-index-url=https://pip.repos.neuron.amazonaws.com && cd ..",
]

[cerebrium.hardware]
region = "us-east-1"
provider = "aws"
compute = "INF2"
cpu = 6
memory = 60.0
gpu_count = 1

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
cooldown = 20

[cerebrium.dependencies.pip]

[cerebrium.dependencies.conda]

[cerebrium.dependencies.apt]
wget = "latest"
