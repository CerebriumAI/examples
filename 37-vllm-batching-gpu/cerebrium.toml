[cerebrium.deployment]
name = "37-vllm-batching-gpu"
python_version = "3.12"
include = ["*"]
exclude = [".*"]
shell_commands = []

[cerebrium.hardware]
cpu = 6
memory = 20.0
compute = "AMPERE_A10"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
cooldown = 10
replica_concurrency = 4

[cerebrium.dependencies.pip]
sentencepiece = "latest"
torch = "latest"
vllm = "latest"
transformers = "latest"
accelerate = "latest"
xformers = "latest"