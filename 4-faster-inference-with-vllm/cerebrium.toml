[cerebrium.deployment]
name = "4-faster-inference-with-vllm"
python_version = "3.12"
include = "[./*, main.py, cerebrium.toml]"
exclude = "[.*]"
shell_commands = []

[cerebrium.hardware]
cpu = 3
memory = 5.0
gpu = "AMPERE_A10"
gpu_count = 1
provider = "aws"
region = "us-east-1"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 5
cooldown = 10

[cerebrium.dependencies.pip]
sentencepiece = "latest"
torch = "latest"
vllm = "latest"
transformers = "latest"
accelerate = "latest"
xformers = "latest"

[cerebrium.dependencies.apt]
git = "latest"