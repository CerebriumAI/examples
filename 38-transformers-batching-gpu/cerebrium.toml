[cerebrium.deployment]
name = "38-transformers-batching-gpu"
python_version = "3.12"
include = ["*"]
exclude = [".*"]
shell_commands = []

[cerebrium.hardware]
cpu = 6
memory = 20.0
compute = "AMPERE_A10"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
cooldown = 10
replica_concurrency = 10 # This should match the batch size

[cerebrium.dependencies.pip]
sentencepiece = "latest"
torch = "latest"
transformers = "latest"
accelerate = "latest"
xformers = "latest"
pydantic = "latest"